{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wn9cH2KuhPQm"
   },
   "source": [
    "# API Scavenger Game\n",
    "\n",
    "## Challenge 1: Fork Languages\n",
    "\n",
    "You will find out how many programming languages are used among all the forks created from the main lab repo of your bootcamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CISPmeFPhPQt"
   },
   "outputs": [],
   "source": [
    "# import libraries here\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHZG8N7hhU1w"
   },
   "source": [
    "Assuming the main lab repo is ironhack-datalabs/mad-oct-2018, you will:\n",
    "\n",
    "#### 1. Obtain the full list of forks created from the main lab repo via Github API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6JuENLGhPQ9"
   },
   "source": [
    "To list forks, we can use the GET method. As explained in the GitHub API documentation, we need to make the request to: GET /repos/:owner/:repo/forks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "II5D8CkQhPQ_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "token='blablabla'\n",
    "username = 'vfarneze'\n",
    "url = 'https://api.github.com/repos/ironhack-datalabs/mad-oct-2018/forks'\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMyRu0p6hPRI"
   },
   "source": [
    "#### 2. Loop the JSON response to find out the language attribute of each fork. Use an array to store the language attributes of each fork.\n",
    "Hint: Each language should appear only once in your array.\n",
    "Print the language array. It should be something like: [\"Python\", \"Jupyter Notebook\", \"HTML\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'node_id', 'name', 'full_name', 'private', 'owner', 'html_url',\n",
       "       'description', 'fork', 'url', 'forks_url', 'keys_url',\n",
       "       'collaborators_url', 'teams_url', 'hooks_url', 'issue_events_url',\n",
       "       'events_url', 'assignees_url', 'branches_url', 'tags_url', 'blobs_url',\n",
       "       'git_tags_url', 'git_refs_url', 'trees_url', 'statuses_url',\n",
       "       'languages_url', 'stargazers_url', 'contributors_url',\n",
       "       'subscribers_url', 'subscription_url', 'commits_url', 'git_commits_url',\n",
       "       'comments_url', 'issue_comment_url', 'contents_url', 'compare_url',\n",
       "       'merges_url', 'archive_url', 'downloads_url', 'issues_url', 'pulls_url',\n",
       "       'milestones_url', 'notifications_url', 'labels_url', 'releases_url',\n",
       "       'deployments_url', 'created_at', 'updated_at', 'pushed_at', 'git_url',\n",
       "       'ssh_url', 'clone_url', 'svn_url', 'homepage', 'size',\n",
       "       'stargazers_count', 'watchers_count', 'language', 'has_issues',\n",
       "       'has_projects', 'has_downloads', 'has_wiki', 'has_pages', 'forks_count',\n",
       "       'mirror_url', 'archived', 'disabled', 'open_issues_count', 'license',\n",
       "       'forks', 'open_issues', 'watchers', 'default_branch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UwZRhw4hPRL"
   },
   "outputs": [],
   "source": [
    "#there are two columns (language and 'languages_url) which contain information about the languages used...\n",
    "\n",
    "# we ill first start with language column, extract all languages and add them uniquely to a list\n",
    "languages = pd.DataFrame(results).loc[:,'language']\n",
    "\n",
    "# your code here\n",
    "langs = []\n",
    "for language in languages:\n",
    "    if language not in langs:\n",
    "        langs.append(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at languages_url\n",
    "languages_url = list(pd.DataFrame(results).loc[:,'languages_url'])\n",
    "\n",
    "# \"languages_url\" is a list of links, each link goes to a json archive which tells which language was used.\n",
    "links = []\n",
    "\n",
    "for link in languages_url:\n",
    "    links.append(requests.get(link).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The languages are: [None, 'Jupyter Notebook', 'HTML', 'Python', 'Shell']\n"
     ]
    }
   ],
   "source": [
    "#each link returned a dictionary, which keys are the langagues, therefore, we can iterate over each dictionary's keys,\n",
    "# and add more detected languages to our list 'langs'\n",
    "links[0].keys()\n",
    "\n",
    "for link in links:\n",
    "    for language in link.keys():\n",
    "        if language not in langs:\n",
    "            langs.append(language)\n",
    "\n",
    "print(f'The languages are: {langs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWWh1AbLhPRU"
   },
   "source": [
    "## Challenge 2: Count Commits\n",
    "Count how many commits were made in the month of january of 2019.\n",
    "\n",
    "Hints: \n",
    "- https://developer.github.com/v3/repos/commits/#list-commits-on-a-repository\n",
    "\n",
    "- GET /repos/:owner/:repo/commits\n",
    "\n",
    "#### 1. Obtain all the commits made in January 2019 via API, which is a JSON array that contains multiple commit objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvBVJbQvhPRW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token='blablabla'\n",
    "username = 'vfarneze'\n",
    "url = 'https://api.github.com/repos/ironhack-datalabs/mad-oct-2018/commits'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = pd.DataFrame(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cp1aYfRShPRb"
   },
   "source": [
    "#### 2. Count how many commit objects are contained in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the dates are stored in commit column\n",
    "#each element of the column is a dictionary, which the key author returns another dictionary\n",
    "#inside this subdictionary, the key \"date\" gives our commit date.\n",
    "\n",
    "#we will store all dates in a list\n",
    "dates = []\n",
    "\n",
    "for element in commits.commit:\n",
    "    dates.append(element['author']['date'])\n",
    "\n",
    "#the dates are in format: YYYY-MM-DDTHH:MM:SSZ, which is a string\n",
    "#we can use regex and look for '2019-01', and if re.findall() finds this date, we can store it\n",
    "\n",
    "jan_commits = []\n",
    "\n",
    "for date in dates:\n",
    "    if len(re.findall('2019-01',date)) ==1:\n",
    "        jan_commits.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "guNZQxx4hPTT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total commit objects are: 30\n",
      "Number of commits done in january: 27\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(f'Number of total commit objects are: {commits.shape[0]}')\n",
    "print(f'Number of commits done in january: {len(jan_commits)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cr6YdvCvhPTZ"
   },
   "source": [
    "## Challenge 3: Hidden Cold Joke\n",
    "\n",
    "Using Python, call Github API to find out the cold joke contained in the 24 secret files in the following repo:\n",
    "\n",
    "https://github.com/ironhack-datalabs/scavenger\n",
    "\n",
    "The filenames of the secret files contain .scavengerhunt and they are scattered in different directories of this repo. The secret files are named from .0001.scavengerhunt to .0024.scavengerhunt. They are scattered randomly throughout this repo. You need to search for these files by calling the Github API, not searching the local files on your computer.\n",
    "\n",
    "#### 1. Find the secret files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96VAucMUhPTb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "response = requests.get('https://api.github.com/repos/ironhack-datalabs/scavenger/contents')\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '.gitignore',\n",
       " 'path': '.gitignore',\n",
       " 'sha': 'e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf',\n",
       " 'size': 10,\n",
       " 'url': 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/.gitignore?ref=master',\n",
       " 'html_url': 'https://github.com/ironhack-datalabs/scavenger/blob/master/.gitignore',\n",
       " 'git_url': 'https://api.github.com/repos/ironhack-datalabs/scavenger/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf',\n",
       " 'download_url': 'https://raw.githubusercontent.com/ironhack-datalabs/scavenger/master/.gitignore',\n",
       " 'type': 'file',\n",
       " 'content': 'LkRTX1N0b3JlCg==\\n',\n",
       " 'encoding': 'base64',\n",
       " '_links': {'self': 'https://api.github.com/repos/ironhack-datalabs/scavenger/contents/.gitignore?ref=master',\n",
       "  'git': 'https://api.github.com/repos/ironhack-datalabs/scavenger/git/blobs/e43b0f988953ae3a84b00331d0ccf5f7d51cb3cf',\n",
       "  'html': 'https://github.com/ironhack-datalabs/scavenger/blob/master/.gitignore'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first step, get all dictionaries\n",
    "folders = response.json()\n",
    "\n",
    "#each folder has a link to be accessed\n",
    "links = [data_dict['url'] for data_dict in folders]\n",
    "\n",
    "# second step, \"open\" all folders\n",
    "folders = [requests.get(link).json() for link in links]\n",
    "\n",
    "#the first element of folders is a '.gitignore' file, not a folder, so we can drop it later\n",
    "folders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now filter all folders, this serves to get rid of any non-folder archive\n",
    "folders = [folder for folder in folders if type(folder) == list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now filter all \"scavengerhunt\" folders, and get rid of unwanted files.\n",
    "#Folders is a list of \"folder\"s, each \"folder\" is also a list containing dictionaries representing github files\n",
    "#each dictionary has a key 'name', which represent the name of the githu file.\n",
    "#if this name contains \"scavengerhunt\", we will keep the file\n",
    "\n",
    "scavenger_files = []\n",
    "\n",
    "for folder in folders:\n",
    "    for file in folder:\n",
    "        \n",
    "        #if scavengerhunt is found, the length of the returned list by re.findall will be 1\n",
    "        #filtering will be True if word is found.\n",
    "        filtering = (len(re.findall('scavengerhunt',str(file['name']))) == 1)\n",
    "        \n",
    "        if filtering:\n",
    "            #we now save every scavengerhunt file's dicts to a list:\n",
    "            scavenger_files.append(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm7O1IHFhPTi"
   },
   "source": [
    "#### 2.  Sort the filenames ascendingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need now to sort, but now we just need to use pandas!\n",
    "#we only need the \"download_url\" to know the text inside the file\n",
    "\n",
    "text_files = pd.DataFrame(scavenger_files).loc[:,['name','download_url']]\n",
    "\n",
    "#we will set the index as 'name' and sort them:\n",
    "text_files = text_files.set_index('name').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqwqQnvShPTt"
   },
   "source": [
    "#### 3. Read the content of each secret files into an array of strings.\n",
    "Since the response is encoded, you will need to send the following information in the header of your request:\n",
    "````python\n",
    "headers = {'Accept': 'application/vnd.github.v3.raw'}\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we \"read\" every file from download_url links.\n",
    "text = [requests.get(link).text for link in text_files['download_url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-h4Qz7ahPT7"
   },
   "source": [
    "#### 4. Concatenate the strings in the array separating each two with a whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we now remove '\\n' which contains in strings\n",
    "treated = [string.replace('\\n','') for string in text]\n",
    "#now we join...\n",
    "final_text = ' '.join(treated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1mXl3TEhPUA"
   },
   "source": [
    "#### 5. Print out the joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JoQ4h2_hPUF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data science, 80 percent of time spent is preparing data, 20 percent of time is spent complaining about the need to prepare data.\n"
     ]
    }
   ],
   "source": [
    "print(final_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

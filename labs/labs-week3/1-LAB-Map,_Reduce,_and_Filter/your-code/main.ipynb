{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wk5IDgMsrJtc"
   },
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hza0fiD_rJti"
   },
   "outputs": [],
   "source": [
    "# Import reduce from functools, numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uG22b-G6rJtn"
   },
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4U5RlJvrJtp"
   },
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = '../data/58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RG45u3K0rJtv"
   },
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGIJTTKlrJtw"
   },
   "outputs": [],
   "source": [
    "prophet = prophet[568:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8zBCI-MFrJt1"
   },
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_7iXvZYrJt2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lr-MA87urJt6"
   },
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3oq4IbtrJt7"
   },
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    return x.split('{')[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HelnQ7CdrJuJ"
   },
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aP1L2CQ8rJuK"
   },
   "outputs": [],
   "source": [
    "prophet_reference = list(map(reference,prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZeXcGmk3rJuN"
   },
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxkA6s1ZrJuO"
   },
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    return x.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnnCEF35rJuR"
   },
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ez96gtU9rJuS"
   },
   "outputs": [],
   "source": [
    "prophet_line = list(map(line_break, prophet_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9dhbACu6rJuW"
   },
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WY6lb6SjrJuX"
   },
   "outputs": [],
   "source": [
    "prophet_flat = [x for lista in prophet_line for x in lista]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7nZFMWUrJua"
   },
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0sZtfMGrJua"
   },
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: True if the word is not in the specified list \n",
    "    and False if the word is in the list.\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mg1jXYJ2rJud"
   },
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET',\n",
       " '',\n",
       " '|Almustafa,',\n",
       " 'chosen',\n",
       " 'beloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own',\n",
       " 'day,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'city',\n",
       " 'of',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to',\n",
       " 'return',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'isle',\n",
       " 'of',\n",
       " 'his',\n",
       " 'birth.',\n",
       " '',\n",
       " 'And',\n",
       " 'in',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'seventh',\n",
       " 'day',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he',\n",
       " 'climbed',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'city',\n",
       " 'walls',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'mist.',\n",
       " '',\n",
       " 'Then',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung',\n",
       " 'open,',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'sea.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'But',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'hill,',\n",
       " 'sadness',\n",
       " 'came',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart:',\n",
       " '',\n",
       " 'How',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'without',\n",
       " 'sorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'spirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " '',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'within',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'long',\n",
       " 'were',\n",
       " 'nights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart',\n",
       " 'from',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without',\n",
       " 'regret?',\n",
       " '',\n",
       " 'Too',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I',\n",
       " 'scattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'too',\n",
       " 'many',\n",
       " 'are',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk',\n",
       " 'naked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'withdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'burden',\n",
       " 'ache.',\n",
       " '',\n",
       " 'It',\n",
       " 'is',\n",
       " 'not',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this',\n",
       " 'day,',\n",
       " 'but',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own',\n",
       " 'hands.',\n",
       " '',\n",
       " 'Nor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,',\n",
       " 'but',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'with',\n",
       " 'thirst.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'Yet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.',\n",
       " '',\n",
       " 'The',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her',\n",
       " 'calls',\n",
       " 'me,',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.',\n",
       " '',\n",
       " 'For',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'crystallize',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'mould.',\n",
       " '',\n",
       " 'Fain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is',\n",
       " 'here.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?',\n",
       " '',\n",
       " 'A',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'tongue',\n",
       " '',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone',\n",
       " 'must',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'ether.',\n",
       " '',\n",
       " 'And',\n",
       " 'alone',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'eagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'sun.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'Now',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'hill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'sea,',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'harbour,',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'mariners,',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.',\n",
       " '',\n",
       " 'And',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'he',\n",
       " 'said:',\n",
       " '',\n",
       " 'Sons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of',\n",
       " 'tides,',\n",
       " '',\n",
       " 'How',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.',\n",
       " 'And',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.',\n",
       " '',\n",
       " 'Ready',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with',\n",
       " 'sails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'wind.',\n",
       " '',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in',\n",
       " 'this',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look',\n",
       " 'cast',\n",
       " 'backward,',\n",
       " '',\n",
       " 'And',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'seafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " '',\n",
       " 'you,',\n",
       " 'vast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,',\n",
       " '',\n",
       " 'Who',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'river',\n",
       " 'stream,',\n",
       " '',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream',\n",
       " 'make,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,',\n",
       " '',\n",
       " 'And',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'boundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'boundless',\n",
       " 'ocean.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " 'men',\n",
       " 'women',\n",
       " 'leaving',\n",
       " 'their',\n",
       " 'fields',\n",
       " 'their',\n",
       " 'vineyards',\n",
       " 'hastening',\n",
       " 'towards',\n",
       " 'city',\n",
       " 'gates.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'heard',\n",
       " 'their',\n",
       " 'voices',\n",
       " 'calling',\n",
       " 'his',\n",
       " 'name,',\n",
       " 'shouting',\n",
       " 'from',\n",
       " 'field',\n",
       " 'to',\n",
       " 'field',\n",
       " 'telling',\n",
       " 'one',\n",
       " 'another',\n",
       " 'of',\n",
       " 'coming',\n",
       " 'of',\n",
       " 'his',\n",
       " 'ship.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'said',\n",
       " 'to',\n",
       " 'himself:',\n",
       " '',\n",
       " 'Shall',\n",
       " 'day',\n",
       " 'of',\n",
       " 'parting',\n",
       " 'be',\n",
       " 'day',\n",
       " 'of',\n",
       " 'gathering?',\n",
       " '',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'it',\n",
       " 'be',\n",
       " 'said',\n",
       " 'that',\n",
       " 'my',\n",
       " 'eve',\n",
       " 'was',\n",
       " 'in',\n",
       " 'truth',\n",
       " 'my',\n",
       " 'dawn?',\n",
       " '',\n",
       " 'And',\n",
       " 'what',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'left',\n",
       " 'his',\n",
       " 'plough',\n",
       " 'in',\n",
       " 'midfurrow,',\n",
       " 'or',\n",
       " 'to',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'stopped',\n",
       " 'wheel',\n",
       " 'of',\n",
       " 'his',\n",
       " 'winepress?',\n",
       " '',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'become',\n",
       " 'tree',\n",
       " 'heavy-laden',\n",
       " 'with',\n",
       " 'fruit',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'gather',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'them?',\n",
       " '',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'my',\n",
       " 'desires',\n",
       " 'flow',\n",
       " 'like',\n",
       " 'fountain',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'fill',\n",
       " 'their',\n",
       " 'cups?',\n",
       " '',\n",
       " 'Am',\n",
       " 'I',\n",
       " 'harp',\n",
       " 'that',\n",
       " 'hand',\n",
       " 'of',\n",
       " 'mighty',\n",
       " 'may',\n",
       " 'touch',\n",
       " 'me,',\n",
       " 'or',\n",
       " 'flute',\n",
       " 'that',\n",
       " 'his',\n",
       " 'breath',\n",
       " 'may',\n",
       " 'pass',\n",
       " 'through',\n",
       " 'me?',\n",
       " '',\n",
       " 'A',\n",
       " 'seeker',\n",
       " 'of',\n",
       " 'silences',\n",
       " 'am',\n",
       " 'I,',\n",
       " 'what',\n",
       " 'treasure',\n",
       " 'have',\n",
       " 'I',\n",
       " 'found',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'dispense',\n",
       " 'with',\n",
       " 'confidence?',\n",
       " '',\n",
       " 'If',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'day',\n",
       " 'of',\n",
       " 'harvest,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'fields',\n",
       " 'have',\n",
       " 'I',\n",
       " 'sowed',\n",
       " 'seed,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'unremembered',\n",
       " 'seasons?',\n",
       " '',\n",
       " 'If',\n",
       " 'this',\n",
       " 'indeed',\n",
       " 'be',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'which',\n",
       " 'I',\n",
       " 'lift',\n",
       " 'up',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'my',\n",
       " 'flame',\n",
       " 'that',\n",
       " 'shall',\n",
       " 'burn',\n",
       " 'therein.',\n",
       " '',\n",
       " 'Empty',\n",
       " 'dark',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " '',\n",
       " 'And',\n",
       " 'guardian',\n",
       " 'of',\n",
       " 'night',\n",
       " 'shall',\n",
       " 'fill',\n",
       " 'it',\n",
       " 'with',\n",
       " 'oil',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'light',\n",
       " 'it',\n",
       " 'also.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'These',\n",
       " 'things',\n",
       " 'he',\n",
       " 'said',\n",
       " 'in',\n",
       " 'words.',\n",
       " 'But',\n",
       " 'much',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'remained',\n",
       " 'unsaid.',\n",
       " 'For',\n",
       " '',\n",
       " 'could',\n",
       " 'not',\n",
       " 'speak',\n",
       " 'his',\n",
       " 'deeper',\n",
       " 'secret.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " '[Illustration:',\n",
       " '0020]',\n",
       " '',\n",
       " 'And',\n",
       " 'when',\n",
       " 'he',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'city',\n",
       " 'all',\n",
       " 'people',\n",
       " 'came',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'him,',\n",
       " 'they',\n",
       " 'were',\n",
       " 'crying',\n",
       " 'out',\n",
       " 'to',\n",
       " 'him',\n",
       " 'as',\n",
       " 'with',\n",
       " 'one',\n",
       " 'voice.',\n",
       " '',\n",
       " 'And',\n",
       " 'elders',\n",
       " 'of',\n",
       " 'city',\n",
       " 'stood',\n",
       " 'forth',\n",
       " 'said:',\n",
       " '',\n",
       " 'Go',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'away',\n",
       " 'from',\n",
       " 'us.',\n",
       " '',\n",
       " 'A',\n",
       " 'noontide',\n",
       " 'have',\n",
       " 'you',\n",
       " 'been',\n",
       " 'in',\n",
       " 'our',\n",
       " 'twilight,',\n",
       " 'your',\n",
       " 'youth',\n",
       " 'has',\n",
       " 'given',\n",
       " 'us',\n",
       " 'dreams',\n",
       " 'to',\n",
       " 'dream.',\n",
       " '',\n",
       " 'No',\n",
       " 'stranger',\n",
       " 'are',\n",
       " 'you',\n",
       " 'among',\n",
       " 'us,',\n",
       " 'nor',\n",
       " 'guest,',\n",
       " 'but',\n",
       " 'our',\n",
       " 'son',\n",
       " 'our',\n",
       " 'dearly',\n",
       " 'beloved.',\n",
       " '',\n",
       " 'Suffer',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'our',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'hunger',\n",
       " 'for',\n",
       " 'your',\n",
       " 'face.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'priests',\n",
       " 'priestesses',\n",
       " 'said',\n",
       " 'unto',\n",
       " 'him:',\n",
       " '',\n",
       " 'Let',\n",
       " 'not',\n",
       " 'waves',\n",
       " 'of',\n",
       " 'sea',\n",
       " 'separate',\n",
       " 'us',\n",
       " 'now,',\n",
       " 'years',\n",
       " 'you',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'in',\n",
       " 'our',\n",
       " 'midst',\n",
       " 'become',\n",
       " 'memory.',\n",
       " '',\n",
       " 'You',\n",
       " 'have',\n",
       " 'walked',\n",
       " 'among',\n",
       " 'us',\n",
       " 'spirit,',\n",
       " '',\n",
       " 'your',\n",
       " 'shadow',\n",
       " 'has',\n",
       " 'been',\n",
       " 'light',\n",
       " 'upon',\n",
       " 'our',\n",
       " 'faces.',\n",
       " '',\n",
       " 'Much',\n",
       " 'have',\n",
       " 'we',\n",
       " 'loved',\n",
       " 'you.',\n",
       " 'But',\n",
       " 'speechless',\n",
       " 'was',\n",
       " 'our',\n",
       " 'love,',\n",
       " 'with',\n",
       " 'veils',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'veiled.',\n",
       " '',\n",
       " 'Yet',\n",
       " 'now',\n",
       " 'it',\n",
       " 'cries',\n",
       " 'aloud',\n",
       " 'unto',\n",
       " 'you,',\n",
       " 'would',\n",
       " 'stand',\n",
       " 'revealed',\n",
       " 'before',\n",
       " 'you.',\n",
       " '',\n",
       " 'And',\n",
       " 'ever',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'that',\n",
       " 'love',\n",
       " 'knows',\n",
       " 'not',\n",
       " 'its',\n",
       " 'own',\n",
       " 'depth',\n",
       " 'until',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'separation.',\n",
       " '',\n",
       " '*****',\n",
       " '',\n",
       " 'And',\n",
       " 'others',\n",
       " 'came',\n",
       " 'also',\n",
       " 'entreated',\n",
       " 'him.',\n",
       " 'But',\n",
       " 'he',\n",
       " 'answered',\n",
       " 'them',\n",
       " 'not.',\n",
       " 'He',\n",
       " 'only',\n",
       " 'bent',\n",
       " 'his',\n",
       " 'head;',\n",
       " 'those',\n",
       " 'who',\n",
       " 'stood',\n",
       " 'near',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'tears',\n",
       " 'falling',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'breast.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'people',\n",
       " 'proceeded',\n",
       " 'towards',\n",
       " 'great',\n",
       " 'square',\n",
       " 'before',\n",
       " 'temple.',\n",
       " '',\n",
       " 'And',\n",
       " 'there',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sanctuary',\n",
       " 'woman',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'was',\n",
       " 'Almitra.',\n",
       " 'And',\n",
       " 'she',\n",
       " 'was',\n",
       " 'seeress.',\n",
       " '',\n",
       " 'And',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'with',\n",
       " 'exceeding',\n",
       " 'tenderness,',\n",
       " 'for',\n",
       " 'it',\n",
       " 'was',\n",
       " 'she',\n",
       " 'who',\n",
       " 'had',\n",
       " 'first',\n",
       " 'sought',\n",
       " 'believed',\n",
       " 'in',\n",
       " 'him',\n",
       " 'when',\n",
       " 'he',\n",
       " 'had',\n",
       " 'been',\n",
       " 'but',\n",
       " 'day',\n",
       " 'in',\n",
       " 'their',\n",
       " 'city.',\n",
       " '',\n",
       " 'hailed',\n",
       " 'him,',\n",
       " 'saying:',\n",
       " '',\n",
       " 'Prophet',\n",
       " 'of',\n",
       " 'God,',\n",
       " 'in',\n",
       " 'quest',\n",
       " 'of',\n",
       " 'uttermost,',\n",
       " 'long',\n",
       " 'have',\n",
       " 'you',\n",
       " 'searched',\n",
       " 'distances',\n",
       " 'for',\n",
       " 'your',\n",
       " 'ship.',\n",
       " '',\n",
       " 'And',\n",
       " 'now',\n",
       " 'your',\n",
       " 'ship',\n",
       " 'has',\n",
       " 'come,',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat))\n",
    "prophet_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxlJQ0jurJue"
   },
   "source": [
    "# Bonus Challenge\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'The'.lower() in ['and', 'the', 'a', 'an']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHpgo8N3rJuf"
   },
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    if x.lower() in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fi_wuSQlrJuj"
   },
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOmYQ9VorJuk"
   },
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    return a + ' ' + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-XVJqmRrJuo"
   },
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aPI0Wd_rJup"
   },
   "outputs": [],
   "source": [
    "prophet_string = reduce(concat_space,prophet_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfU7l1AQrJus"
   },
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will connect to Ironhack's database and retrieve the data from the *pollution* database. Select the *beijing_pollution* table and retrieve its data. The data is also available at https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3GvzGWUrJut"
   },
   "outputs": [],
   "source": [
    "beijin = pd.read_csv('../data/beijing_pollution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8297k0TYrJuv"
   },
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qTif-IurJuw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beijin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ByENRWf6rJu4"
   },
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ],
    "colab": {},
    "colab_type": "code",
    "id": "YOST-vh5rJu5"
   },
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    \n",
    "    return x/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvcnm30PrJu_"
   },
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEjehpzGrJvA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>9.665417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>9.907500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>10.112500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>10.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>10.410417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Iws   Is   Ir\n",
       "0       0.074583  0.0  0.0\n",
       "1       0.205000  0.0  0.0\n",
       "2       0.279583  0.0  0.0\n",
       "3       0.410000  0.0  0.0\n",
       "4       0.540417  0.0  0.0\n",
       "...          ...  ...  ...\n",
       "43819   9.665417  0.0  0.0\n",
       "43820   9.907500  0.0  0.0\n",
       "43821  10.112500  0.0  0.0\n",
       "43822  10.280000  0.0  0.0\n",
       "43823  10.410417  0.0  0.0\n",
       "\n",
       "[43824 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly = beijin.loc[:,['Iws','Is','Ir']].apply(hourly)\n",
    "pm25_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a_HbwX40rJvG"
   },
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA19K30SrJvI"
   },
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    return np.std(list(x))/(x.count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iws    4.754929e-05\n",
       "Is     7.229519e-07\n",
       "Ir     1.346183e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly.apply(sample_sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checking individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.754929306240349e-05"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sd(pm25_hourly.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.229518565757495e-07"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sd(pm25_hourly.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3461828955540504e-06"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sd(pm25_hourly.iloc[:,2])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

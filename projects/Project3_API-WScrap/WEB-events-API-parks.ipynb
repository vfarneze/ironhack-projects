{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of promissing regions:\n",
    "\n",
    "- new york\n",
    "- los angeles\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function has to get\n",
    "primeira parte:\n",
    "- get event name\n",
    "- get event date\n",
    "- get event local\n",
    "- get event website\n",
    "\n",
    "\n",
    "segunda parte:\n",
    "- Get adress\n",
    "- get lat long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_events(months,cities,country,year=2020):\n",
    "    '''\n",
    "    This function shows all the eventes listed on www.residentadvisor.net.\n",
    "    It returns a dataframe listing event's date, name, place, city, country and link.\n",
    "    User must insert dates to be searched as a list, the country and a list of cities name,\n",
    "    although it has default values inserted.\n",
    "    \n",
    "    months must be a list with the number of the months, like: [01, 02, 03, 04, ... 11, 12]\n",
    "    \n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    print('Extract_events progress:')\n",
    "    for city in tqdm(cities):\n",
    "\n",
    "        for month in months:\n",
    "\n",
    "            url = f'https://www.residentadvisor.net/events/{country}/{city}/month/2020-'+ f'{month}' +'-01'\n",
    "            \n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content)\n",
    "\n",
    "\n",
    "            # the body of the html where our info is, is located at  <div id=\"event-listing\" class=\"fl col4\">\n",
    "            minisoup = soup.find_all('div',attrs={'id':'event-listing'})\n",
    "            \n",
    "            #we first check if there is any events on the searched month... if so, we analyse the soup\n",
    "            if len(minisoup) != 0:\n",
    "                minisoup = minisoup[0]\n",
    "                #now we analyse line by line: <article class=\"event-item pick clearfix  tickets-bkg-logo small-item\" itemscope=\"\"...>\n",
    "                html_chunks = minisoup.find_all('article')\n",
    "                \n",
    "                for html_chunk in html_chunks:\n",
    "\n",
    "                    link = 'https://www.residentadvisor.net' + html_chunk.find_all('a')[0]['href'].split('#tickets')[0]\n",
    "                    event_date = html_chunk.find_all('time')[0].text.split('T')[0]\n",
    "                    event_name = html_chunk.find_all('h1')[0].text.split('at')[0].strip()\n",
    "                    event_place = html_chunk.find_all('h1')[0].text.split('at')[1].strip()\n",
    "\n",
    "                    mini_df = pd.DataFrame({'date' : [event_date],\n",
    "                                        'name' : [event_name],\n",
    "                                        'place': [event_place],\n",
    "                                            'city' : [city],\n",
    "                                            'country' : [country],\n",
    "                                        'link': [link]})\n",
    "                    df = pd.concat([df, mini_df])\n",
    "\n",
    "    print('------------- Process concluded! ------------')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_info(links):\n",
    "    '''\n",
    "    This function checks links of events and gets, when existing, info about:\n",
    "    Date, Adress, Minium Age, Promoters, line-up, event description and Cost'\n",
    "    All info is returned as a dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for link in tqdm(links):\n",
    "\n",
    "        temp_dict = {}\n",
    "\n",
    "        url = link\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "\n",
    "        # all we need is inside <ul class=\"clearfix\">, the first one\n",
    "        chunk = soup.find_all('ul',attrs={'class':'clearfix'})[0]\n",
    "        infos = [piece.text for piece in chunk.find_all('li')]\n",
    "\n",
    "        for info in infos:\n",
    "            key = info.split('/')[0].strip()\n",
    "            value = info.split('/')[1]\n",
    "            temp_dict[key] = value\n",
    "\n",
    "        temp_dict['lineup'] = soup.find_all('p',attrs={'class':'lineup'})[0].text.replace('\\n',', ')\n",
    "        temp_dict['description'] = soup.find_all('p')[1].text.strip().replace('\\n',' / ')\n",
    "        temp_dict['Date'] = temp_dict['Date'].split('2020')[-1]\n",
    "\n",
    "        mini_df = pd.DataFrame(temp_dict,index=[0])\n",
    "        df = pd.concat([df, mini_df])\n",
    "    \n",
    "    # Renamin columns\n",
    "    df.columns = ['event_time', 'Address', 'Minimum age', 'Promoters', 'lineup', 'description', 'Cost']\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: locationiq.com\n",
    "\n",
    "GET https://us1.locationiq.com/v1/search.php?key=YOUR_PRIVATE_TOKEN&q=SEARCH_STRING&format=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_us(search_string, token='tokentokentoken', sleeptime=1):\n",
    "    '''\n",
    "    This function receives an address and returns latitude and longitude coordinates as a tuple.\n",
    "    Sleep is needed to avoid excess requests to API, since is limited with current key.\n",
    "    Going too fast makes the API return not what is expected, which ends up in error\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import time\n",
    "    time.sleep(sleeptime)\n",
    "    \n",
    "    \n",
    "    if search_string == 'unreadable':\n",
    "        return np.nan\n",
    "    \n",
    "    url = f'https://us1.locationiq.com/v1/search.php?key={token}&q={search_string}&format=json'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    #if response is a json\n",
    "    try:\n",
    "        coordinates = (response.json()[0]['lat'],response.json()[0]['lon'])\n",
    "        return coordinates\n",
    "\n",
    "    #if response is 'xml'\n",
    "    except:\n",
    "        soup = BeautifulSoup(response.content,'xml')\n",
    "        \n",
    "        if (response.text.split('\"')[3] == 'Unable to geocode'):\n",
    "            print(f'\\nCould not get coordinates from: {search_string}!')\n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "            values = soup.find_all('place')[0]['boundingbox'].split(',')\n",
    "            coordinates = (values[0],values[2])\n",
    "            return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(response.text.split('\"')[3] == 'Unable to geocode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "get_coordinates_us('1809 Minor Ave #10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "get_coordinates_us('428 S Hewitt St, Los Angeles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API: https://www.hikingproject.com/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_hiking_parks(coord, address_id, key='KEYKEYKEYKEYKEYEKEEKEYEJE', maxD = 20):\n",
    "    '''\n",
    "    This function receives latitude and longitude coordinates and returns a dataframe containing information\n",
    "    regarding parks near the location suited for camping or hinking.\n",
    "    If there are no parks near the coordinates given, an empty dataframe \n",
    "    \n",
    "    maxD - Max distance, in miles, from lat, lon. Default: 30. Max: 200.\n",
    "    '''\n",
    "    \n",
    "    import numpy as np  \n",
    "    \n",
    "    url = f'https://www.hikingproject.com/data/get-campgrounds?lat={coord[0]}&lon={coord[1]}&maxDistance={maxD}&key={key}'\n",
    "    response = requests.request('get',url)\n",
    "    success = response.json()['success']\n",
    "    campgrounds = response.json()['campgrounds']\n",
    "    \n",
    "    if success == 1:\n",
    "        df = pd.DataFrame(campgrounds)\n",
    "        df['address'] = address_id\n",
    "#         df = df.set_index(keys='event near').reset_index()\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        empty_dict = {\"address\":address_id,\n",
    "                      \"id\": np.nan,\n",
    "                      \"name\":  np.nan,\n",
    "                      \"isBookable\": np.nan,\n",
    "                      \"isCampground\": np.nan,\n",
    "                      \"location\": np.nan,\n",
    "                      \"latitude\": np.nan,\n",
    "                      \"longitude\": np.nan,\n",
    "                      \"url\": np.nan,\n",
    "                      \"imgUrl\": np.nan,\n",
    "                      \"numCampsites\": np.nan}\n",
    "        \n",
    "        return pd.DataFrame(empty_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing:\n",
    "coordinates = ('34.04272815', '-118.234942180885')\n",
    "get_hiking_parks(coord=coordinates,address_id='FiestaFiesta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address_us(dataframe):\n",
    "    '''\n",
    "    This function gets the dataframe of information from events and cleans the address column.\n",
    "    It returns a dataframe with the same other columns too.\n",
    "    '''\n",
    "    \n",
    "    #cleaning Address column from '\\xa0 United States of America'\n",
    "    df_infos = dataframe.copy()\n",
    "    df_infos.loc[:,'Address'] = df_infos.loc[:,'Address'].apply(lambda x: x.split('\\xa0')[0])\n",
    "\n",
    "    #second, every address starts with a number, so anything before this number is the name of the place. \n",
    "    #Also, in case no number is found, the information will be rewritten as 'unreadable'\n",
    "    #one last thing, the numbers must be followed by a letter, which avoid getting pieces of names that contain numbers (like 'bar 666')\n",
    "    pattern = '\\d\\d?\\d?\\d?\\w?\\w? \\d?\\d?\\d?[a-zA-Z].*'\n",
    "    df_infos.loc[:,'Address'] = df_infos.loc[:,'Address'].apply(lambda x: re.findall(pattern,x)[0] if len(re.findall(pattern,x)) !=0 else 'unreadable')\n",
    "\n",
    "    return df_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search data\n",
    "dates = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "list_of_cities = ['seattle', 'houston','newyork','detroit','losangeles','orlando','sanfrancisco','sandiego']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting events\n",
    "events = extract_events(months=dates,country='us',cities=list_of_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting events info\n",
    "events_info = get_event_info(links = events.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning Address column\n",
    "events_info_treated =  clean_address_us(events_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting now coordinates. We need to use unique addresses to avoid double requesting the API\n",
    "to_request = events_info_treated.Address.unique()\n",
    "temp_dict = {}\n",
    "\n",
    "for request in tqdm(to_request):\n",
    "    temp_dict[request] = get_coordinates_us(request)\n",
    "\n",
    "events_info_treated['coordinates'] = events_info_treated.loc[:,'Address'].apply(lambda x: temp_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining tables side by side\n",
    "event_list = pd.concat([events,events_info_treated],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating dataframe of parks. This dataframe will be connected by an address ID, since parties and\n",
    "# places can have the same names but different addresses\n",
    "\n",
    "df_temp = event_list.loc[:,['Address','coordinates']].dropna().drop_duplicates('Address')\n",
    "\n",
    "dfparks = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(df_temp.shape[0])):\n",
    "    coord = df_temp.loc[:,'coordinates'].iloc[i]\n",
    "    address_id = df_temp.loc[:,'Address'].iloc[i]\n",
    "    mini_df = get_hiking_parks(coord, address_id,maxD=30)\n",
    "    dfparks = pd.concat([dfparks, mini_df])\n",
    "\n",
    "dfparks = dfparks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now saving the obtained data in csvs\n",
    "event_list.to_csv(r'events_data.csv')\n",
    "dfparks.to_csv(r'parks_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save to a postgresSQL DB\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:123qweasd@localhost/Projeto_API_WEBscraping')\n",
    "conn = engine.connect()\n",
    "\n",
    "event_list.to_sql('events_data', conn, index=False, if_exists='replace')\n",
    "dfparks.to_sql('parks_data', conn, index=False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

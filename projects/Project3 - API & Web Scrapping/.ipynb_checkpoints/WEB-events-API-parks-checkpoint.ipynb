{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "List of promissing regions:\n",
    "\n",
    "- new york\n",
    "- los angeles\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "the function has to get\n",
    "primeira parte:\n",
    "- get event name\n",
    "- get event date\n",
    "- get event local\n",
    "- get event website\n",
    "\n",
    "\n",
    "segunda parte:\n",
    "- Get adress\n",
    "- get lat long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def extract_events(months,cities,country,year=2020):\n",
    "    '''\n",
    "    This function shows all the eventes listed on www.residentadvisor.net.\n",
    "    It returns a dataframe listing event's date, name, place, city, country and link.\n",
    "    User must insert dates to be searched as a list, the country and a list of cities name,\n",
    "    although it has default values inserted.\n",
    "    \n",
    "    months must be a list with the number of the months, like: [01, 02, 03, 04, ... 11, 12]\n",
    "    \n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    print('Extract_events progress:')\n",
    "    for city in tqdm(cities):\n",
    "\n",
    "        for month in months:\n",
    "\n",
    "            url = f'https://www.residentadvisor.net/events/{country}/{city}/month/2020-'+ f'{month}' +'-01'\n",
    "            \n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content)\n",
    "\n",
    "\n",
    "            # the body of the html where our info is, is located at  <div id=\"event-listing\" class=\"fl col4\">\n",
    "            minisoup = soup.find_all('div',attrs={'id':'event-listing'})\n",
    "            \n",
    "            #we first check if there is any events on the searched month... if so, we analyse the soup\n",
    "            if len(minisoup) != 0:\n",
    "                minisoup = minisoup[0]\n",
    "                #now we analyse line by line: <article class=\"event-item pick clearfix  tickets-bkg-logo small-item\" itemscope=\"\"...>\n",
    "                html_chunks = minisoup.find_all('article')\n",
    "                \n",
    "                for html_chunk in html_chunks:\n",
    "\n",
    "                    link = 'https://www.residentadvisor.net' + html_chunk.find_all('a')[0]['href'].split('#tickets')[0]\n",
    "                    event_date = html_chunk.find_all('time')[0].text.split('T')[0]\n",
    "                    event_name = html_chunk.find_all('h1')[0].text.split('at')[0].strip()\n",
    "                    event_place = html_chunk.find_all('h1')[0].text.split('at')[1].strip()\n",
    "\n",
    "                    mini_df = pd.DataFrame({'date' : [event_date],\n",
    "                                        'name' : [event_name],\n",
    "                                        'place': [event_place],\n",
    "                                            'city' : [city],\n",
    "                                            'country' : [country],\n",
    "                                        'link': [link]})\n",
    "                    df = pd.concat([df, mini_df])\n",
    "\n",
    "    print('------------- Process concluded! ------------')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_event_info(links):\n",
    "    '''\n",
    "    This function checks links of events and gets, when existing, info about:\n",
    "    Date, Adress, Minium Age, Promoters, line-up, event description and Cost'\n",
    "    All info is returned as a dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for link in tqdm(links):\n",
    "\n",
    "        temp_dict = {}\n",
    "\n",
    "        url = link\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "\n",
    "        # all we need is inside <ul class=\"clearfix\">, the first one\n",
    "        chunk = soup.find_all('ul',attrs={'class':'clearfix'})[0]\n",
    "        infos = [piece.text for piece in chunk.find_all('li')]\n",
    "\n",
    "        for info in infos:\n",
    "            key = info.split('/')[0].strip()\n",
    "            value = info.split('/')[1]\n",
    "            temp_dict[key] = value\n",
    "\n",
    "        temp_dict['lineup'] = soup.find_all('p',attrs={'class':'lineup'})[0].text.replace('\\n',', ')\n",
    "        temp_dict['description'] = soup.find_all('p')[1].text.strip().replace('\\n',' / ')\n",
    "        temp_dict['Date'] = temp_dict['Date'].split('2020')[-1]\n",
    "\n",
    "        mini_df = pd.DataFrame(temp_dict,index=[0])\n",
    "        df = pd.concat([df, mini_df])\n",
    "    \n",
    "    # Renamin columns\n",
    "    df.columns = ['event_time', 'Address', 'Minimum age', 'Promoters', 'lineup', 'description', 'Cost']\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# API: locationiq.com\n",
    "\n",
    "GET https://us1.locationiq.com/v1/search.php?key=YOUR_PRIVATE_TOKEN&q=SEARCH_STRING&format=json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_coordinates_us(search_string, token='tokentokentoken', sleeptime=1):\n",
    "    '''\n",
    "    This function receives an address and returns latitude and longitude coordinates as a tuple.\n",
    "    Sleep is needed to avoid excess requests to API, since is limited with current key.\n",
    "    Going too fast makes the API return not what is expected, which ends up in error\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import time\n",
    "    time.sleep(sleeptime)\n",
    "    \n",
    "    \n",
    "    if search_string == 'unreadable':\n",
    "        return np.nan\n",
    "    \n",
    "    url = f'https://us1.locationiq.com/v1/search.php?key={token}&q={search_string}&format=json'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    #if response is a json\n",
    "    try:\n",
    "        coordinates = (response.json()[0]['lat'],response.json()[0]['lon'])\n",
    "        return coordinates\n",
    "\n",
    "    #if response is 'xml'\n",
    "    except:\n",
    "        soup = BeautifulSoup(response.content,'xml')\n",
    "        \n",
    "        if (response.text.split('\"')[3] == 'Unable to geocode'):\n",
    "            print(f'\\nCould not get coordinates from: {search_string}!')\n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "            values = soup.find_all('place')[0]['boundingbox'].split(',')\n",
    "            coordinates = (values[0],values[2])\n",
    "            return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(response.text.split('\"')[3] == 'Unable to geocode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('47.6168713', '-122.3311299')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "get_coordinates_us('1809 Minor Ave #10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('34.04272815', '-118.234942180885')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "get_coordinates_us('428 S Hewitt St, Los Angeles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# API: https://www.hikingproject.com/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_hiking_parks(coord, address_id, key='KEYKEYKEYKEYKEYEKEEKEYEJE', maxD = 20):\n",
    "    '''\n",
    "    This function receives latitude and longitude coordinates and returns a dataframe containing information\n",
    "    regarding parks near the location suited for camping or hinking.\n",
    "    If there are no parks near the coordinates given, an empty dataframe \n",
    "    \n",
    "    maxD - Max distance, in miles, from lat, lon. Default: 30. Max: 200.\n",
    "    '''\n",
    "    \n",
    "    import numpy as np  \n",
    "    \n",
    "    url = f'https://www.hikingproject.com/data/get-campgrounds?lat={coord[0]}&lon={coord[1]}&maxDistance={maxD}&key={key}'\n",
    "    response = requests.request('get',url)\n",
    "    success = response.json()['success']\n",
    "    campgrounds = response.json()['campgrounds']\n",
    "    \n",
    "    if success == 1:\n",
    "        df = pd.DataFrame(campgrounds)\n",
    "        df['address'] = address_id\n",
    "#         df = df.set_index(keys='event near').reset_index()\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        empty_dict = {\"address\":address_id,\n",
    "                      \"id\": np.nan,\n",
    "                      \"name\":  np.nan,\n",
    "                      \"isBookable\": np.nan,\n",
    "                      \"isCampground\": np.nan,\n",
    "                      \"location\": np.nan,\n",
    "                      \"latitude\": np.nan,\n",
    "                      \"longitude\": np.nan,\n",
    "                      \"url\": np.nan,\n",
    "                      \"imgUrl\": np.nan,\n",
    "                      \"numCampsites\": np.nan}\n",
    "        \n",
    "        return pd.DataFrame(empty_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>isBookable</th>\n",
       "      <th>isCampground</th>\n",
       "      <th>location</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>url</th>\n",
       "      <th>imgUrl</th>\n",
       "      <th>numCampsites</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115201858</td>\n",
       "      <td>Nino Picnic Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>La Ca単ada Flintridge, California</td>\n",
       "      <td>34.2264</td>\n",
       "      <td>-118.1799</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115201858...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7056497_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115201859</td>\n",
       "      <td>Paul Little Picnic Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>La Ca単ada Flintridge, California</td>\n",
       "      <td>34.2296</td>\n",
       "      <td>-118.1769</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115201859...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7056496_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115201857</td>\n",
       "      <td>Echo Mountain Picnic Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Altadena, California</td>\n",
       "      <td>34.2118</td>\n",
       "      <td>-118.1211</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115201857...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7033510_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115210435</td>\n",
       "      <td>Angeles National Forest Supervisor's Office</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Arcadia, California</td>\n",
       "      <td>34.1481</td>\n",
       "      <td>-118.0338</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115210435...</td>\n",
       "      <td>https://www.rei.com/assets/camp/images/campgro...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115201871</td>\n",
       "      <td>Inspiration Point Interpretive Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Altadena, California</td>\n",
       "      <td>34.2215</td>\n",
       "      <td>-118.1094</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115201871...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7033510_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115210368</td>\n",
       "      <td>Mt. Wilson Skyline Park Picnic Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sierra Madre, California</td>\n",
       "      <td>34.2237</td>\n",
       "      <td>-118.0619</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115210368...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7007359_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115201861</td>\n",
       "      <td>Chantry Flat Picnic Site</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sierra Madre, California</td>\n",
       "      <td>34.1956</td>\n",
       "      <td>-118.0234</td>\n",
       "      <td>https://www.rei.com/campgrounds/camp/115201861...</td>\n",
       "      <td>https://cdn-files.apstatic.com/hike/7056499_sm...</td>\n",
       "      <td>0</td>\n",
       "      <td>FiestaFiesta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                         name  isBookable  \\\n",
       "0  115201858                             Nino Picnic Site       False   \n",
       "1  115201859                      Paul Little Picnic Site       False   \n",
       "2  115201857                    Echo Mountain Picnic Site       False   \n",
       "3  115210435  Angeles National Forest Supervisor's Office       False   \n",
       "4  115201871          Inspiration Point Interpretive Site       False   \n",
       "5  115210368          Mt. Wilson Skyline Park Picnic Site       False   \n",
       "6  115201861                     Chantry Flat Picnic Site       False   \n",
       "\n",
       "   isCampground                          location  latitude  longitude  \\\n",
       "0         False  La Ca単ada Flintridge, California   34.2264  -118.1799   \n",
       "1         False  La Ca単ada Flintridge, California   34.2296  -118.1769   \n",
       "2         False              Altadena, California   34.2118  -118.1211   \n",
       "3         False               Arcadia, California   34.1481  -118.0338   \n",
       "4         False              Altadena, California   34.2215  -118.1094   \n",
       "5         False          Sierra Madre, California   34.2237  -118.0619   \n",
       "6         False          Sierra Madre, California   34.1956  -118.0234   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.rei.com/campgrounds/camp/115201858...   \n",
       "1  https://www.rei.com/campgrounds/camp/115201859...   \n",
       "2  https://www.rei.com/campgrounds/camp/115201857...   \n",
       "3  https://www.rei.com/campgrounds/camp/115210435...   \n",
       "4  https://www.rei.com/campgrounds/camp/115201871...   \n",
       "5  https://www.rei.com/campgrounds/camp/115210368...   \n",
       "6  https://www.rei.com/campgrounds/camp/115201861...   \n",
       "\n",
       "                                              imgUrl  numCampsites  \\\n",
       "0  https://cdn-files.apstatic.com/hike/7056497_sm...             0   \n",
       "1  https://cdn-files.apstatic.com/hike/7056496_sm...             0   \n",
       "2  https://cdn-files.apstatic.com/hike/7033510_sm...             0   \n",
       "3  https://www.rei.com/assets/camp/images/campgro...             0   \n",
       "4  https://cdn-files.apstatic.com/hike/7033510_sm...             0   \n",
       "5  https://cdn-files.apstatic.com/hike/7007359_sm...             0   \n",
       "6  https://cdn-files.apstatic.com/hike/7056499_sm...             0   \n",
       "\n",
       "        address  \n",
       "0  FiestaFiesta  \n",
       "1  FiestaFiesta  \n",
       "2  FiestaFiesta  \n",
       "3  FiestaFiesta  \n",
       "4  FiestaFiesta  \n",
       "5  FiestaFiesta  \n",
       "6  FiestaFiesta  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing:\n",
    "coordinates = ('34.04272815', '-118.234942180885')\n",
    "get_hiking_parks(coord=coordinates,address_id='FiestaFiesta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_address_us(dataframe):\n",
    "    '''\n",
    "    This function gets the dataframe of information from events and cleans the address column.\n",
    "    It returns a dataframe with the same other columns too.\n",
    "    '''\n",
    "    \n",
    "    #cleaning Address column from '\\xa0 United States of America'\n",
    "    df_infos = dataframe.copy()\n",
    "    df_infos.loc[:,'Address'] = df_infos.loc[:,'Address'].apply(lambda x: x.split('\\xa0')[0])\n",
    "\n",
    "    #second, every address starts with a number, so anything before this number is the name of the place. \n",
    "    #Also, in case no number is found, the information will be rewritten as 'unreadable'\n",
    "    #one last thing, the numbers must be followed by a letter, which avoid getting pieces of names that contain numbers (like 'bar 666')\n",
    "    pattern = '\\d\\d?\\d?\\d?\\w?\\w? \\d?\\d?\\d?[a-zA-Z].*'\n",
    "    df_infos.loc[:,'Address'] = df_infos.loc[:,'Address'].apply(lambda x: re.findall(pattern,x)[0] if len(re.findall(pattern,x)) !=0 else 'unreadable')\n",
    "\n",
    "    return df_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# search data\n",
    "dates = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "list_of_cities = ['seattle', 'houston','newyork','detroit','losangeles','orlando','sanfrancisco','sandiego']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting events\n",
    "events = extract_events(months=dates,country='us',cities=list_of_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# getting events info\n",
    "events_info = get_event_info(links = events.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# cleaning Address column\n",
    "events_info_treated =  clean_address_us(events_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8f58abb13d4c7ba6b1f63a00513102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=562.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not get coordinates from: 269 Norman Ave Btwn Monitor St & Kingsland Ave Brooklyn, NY 11222, United States!\n",
      "\n",
      "Could not get coordinates from: 88 Palace 88 East Broadway; New York, NY 10002; United States!\n",
      "\n",
      "Could not get coordinates from: 473 Broadway Street, San Francisco, CA 94133, United States!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting now coordinates. We need to use unique addresses to avoid double requesting the API\n",
    "to_request = events_info_treated.Address.unique()\n",
    "temp_dict = {}\n",
    "\n",
    "for request in tqdm(to_request):\n",
    "    temp_dict[request] = get_coordinates_us(request)\n",
    "\n",
    "events_info_treated['coordinates'] = events_info_treated.loc[:,'Address'].apply(lambda x: temp_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# joining tables side by side\n",
    "event_list = pd.concat([events,events_info_treated],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906acc35d1aa4ee4a4f01147544a4056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=558.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# creating dataframe of parks. This dataframe will be connected by an address ID, since parties and\n",
    "# places can have the same names but different addresses\n",
    "\n",
    "df_temp = event_list.loc[:,['Address','coordinates']].dropna().drop_duplicates('Address')\n",
    "\n",
    "dfparks = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(df_temp.shape[0])):\n",
    "    coord = df_temp.loc[:,'coordinates'].iloc[i]\n",
    "    address_id = df_temp.loc[:,'Address'].iloc[i]\n",
    "    mini_df = get_hiking_parks(coord, address_id,maxD=30)\n",
    "    dfparks = pd.concat([dfparks, mini_df])\n",
    "\n",
    "dfparks = dfparks.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#now saving the obtained data in csvs\n",
    "event_list.to_csv(r'events_data.csv')\n",
    "dfparks.to_csv(r'parks_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#now save to a postgresSQL DB\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:123qweasd@localhost/Projeto_API_WEBscraping')\n",
    "conn = engine.connect()\n",
    "\n",
    "event_list.to_sql('events_data', conn, index=False, if_exists='replace')\n",
    "dfparks.to_sql('parks_data', conn, index=False, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
